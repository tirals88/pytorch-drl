{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirals88/pytorch-drl/blob/main/DRL_Chap3_2_CartPole_Q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'PyTorch를 활용한 강화학습/심층강화학습 실전입문' 책 스터디 내용을 Google Colab으로 정리하여 올립니다.\n",
        "\n",
        "Github 예제 코드 주소 : 'https://github.com/wikibook/pytorch-drl'\n",
        "\n",
        "PyTorch를 활용한 강화학습/심층강화학습 실전입문\n",
        "\n",
        "https://wikibook.co.kr/pytorch-drl/"
      ],
      "metadata": {
        "id": "_urokx68V926"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***가상환경 구현 및 함수 수정***"
      ],
      "metadata": {
        "id": "AJTGfJ9a0Spf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib -downgrade\n",
        "\n",
        "!pip install matplotlib==3.4.2"
      ],
      "metadata": {
        "id": "vt4pA63J0hb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y xvfb #server install\n",
        "import sys\n",
        "\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "  !apt update && apt install -y libpq-dev libsdl2-dev swig xorg-dev xvfb\n",
        "  %pip install -U tf-agents pyvirtualdisplay\n",
        "  %pip install -U gym>=0.21.0\n",
        "  %pip install -U gym[box2d,atari, accept-rom-license]\n",
        "\n",
        "!xvfb-run -s \"-screen 0 1400x900x24\" jupyter notebook"
      ],
      "metadata": {
        "id": "3laxoCpM0hh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***display_frames_as_gif 함수 정의***"
      ],
      "metadata": {
        "id": "lM2T5YjW0uoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 구현에 사용할 패키지 임포트\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import gym"
      ],
      "metadata": {
        "id": "4yVtD8BU0881"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 애니메이션을 만드는 함수\n",
        "# 참고 URL : https://github.com/patrickmineault/xcorr-notebooks/blob/master/notebooks/Render%20OpenAI%20gym%20as%20GIF.ipynb\n",
        "!pip install JSAnimation\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import display\n",
        "\n",
        "#새로 정의한 display_animtaion 함수\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_animation(anim):\n",
        "  return HTML(anim.to_jshtml())"
      ],
      "metadata": {
        "id": "qllUOfzc1O8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_frames_as_gif(frames):\n",
        "  \"\"\"\n",
        "  Displays a list of frames as a gif, with controls\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(frames[0].shape[1]/48.0, frames[0].shape[0]/48.0), dpi=72)\n",
        "  patch = plt.imshow(frames[0])\n",
        "  plt.axis('off')\n",
        "\n",
        "  def animate(i):\n",
        "    patch.set_data(frames[i])\n",
        "\n",
        "  anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=20)\n",
        "\n",
        "  anim.save('movie_cartpole.mp4') #애니메이션을 저장하는 부분\n",
        "  display(display_animation(anim)) #수정된 부분"
      ],
      "metadata": {
        "id": "GCZDAaTS1a3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 다변수, 연속값 상태를 표형식으로 나타내기"
      ],
      "metadata": {
        "id": "Z3Xfj4q1aPS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CartPole 의 상태\n",
        "\n",
        "이전 장에서 다뤘던 미로 태스크에서 상태는 에이전트가 어느 칸에 위치했는지를 변수 하나로 나타냈으며 0~8의 단순 이산값이었다. 그러나 역진자 태스크에서는 더 복잡하게 상태가 정의된다.\n",
        "\n",
        "CartPole 태스크는 observation 변수에 상태를 저장한다. env.step(action)은 게임 환경을 1단계 진행시키는 명령어로 action = 0 일 때 수레를 왼쪽으로 움직이는 것이고 1 일 때 오른쪽으로 움직이는 것에 해당한다.\n",
        "\n",
        "env.step(action) 은 observation, reward, done, info 라는 4개의 변수를 반환한다. observation은 수레와 봉의 상태를 나타내며 상태는 다시 4개의 변수로 이루어져 있다. 이는 수레의 위치 (-2.4 ~ 2.4), 수레의 속도 (-inf ~ inf), 봉의 각도 (-41.8도 ~ 41.8), 봉의 가속도 (-inf ~ inf)이다.\n",
        "\n",
        "reward는 즉각보상이며 action을 실행한 후에 수레의 위치가 $\\pm2.4$ 범위 안에 있고 봉이 $20.9$도 이상 기울어 있지 않다면 보상 1을 받는다. 반대의 경우, 보상은 0이 된다.\n",
        "\n",
        "done 은 게임 종료 여부를 나타내며, 200단계를 초과하거나, 보상이 0일 될 때 게임이 종료되어 done 의 값이 True가 된다.\n",
        "\n",
        "info 는 디버깅 등에 필요한 정보를 담은 변수이다."
      ],
      "metadata": {
        "id": "ia9hsu7NSnFG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N33fCtic1lfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}